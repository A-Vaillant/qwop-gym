---
# [int] (optional) Env seed (auto-generated if blank)
seed: ~

# [string] (optional) Unique ID of this run (auto-generated if blank)
run_id: ~

# [string] (optional) Continue training of a previously trained model
model_load_file: ~

# [string] Directory template to save the trained model, metadata and
# tensorboard logs. If the template contains {run_id} or {seed} placeholders,
# they will be replaced with the corresponding runtime values.
out_dir_template: "data/SAC-{run_id}"

# [bool] Log tensorboard data
log_tensorboard: true

# [int] Training duration (set to a minimum of 10-20M for PPO)
total_timesteps: 100_000

# [int] (optional) Force env termination on the Nth step of an episode
max_episode_steps: 1000

# [int] Number of times the model will be saved during training
# Example: 5 means save at 20%, 40%, 60%, 80% and 100% progress
n_checkpoints: 5

# A2C algorithm parameters (used only if `model_load_file` is blank)
# https://stable-baselines3.readthedocs.io/en/master/modules/a2c.html#stable_baselines3.a2c.A2C
learner_kwargs:
  policy: "MlpPolicy"
  n_steps: 5
  gamma: 0.99
  gae_lambda: 1.0
  ent_coef: 0.0
  vf_coef: 0.5
  max_grad_norm: 0.5
  rms_prop_eps: 0.00001
  use_rms_prop: true
  use_sde: false
  sde_sample_freq: -1
  normalize_advantage: false
  stats_window_size: 100

# (string) Schedule for the learning_rate as a function of the progress remaining.
# Format is one of:
#   const_V0
#   lin_decay_V0_V1_F
#   exp_decay_V0_V1_F_N
# where:
#   V0 = initial lr value
#   V1 = final lr value
#   F = fraction of the total training time to fully decay from V0 to V1
#   N = number of decay steps (used in exp_decay only)
# Examples:
#   * "const_0.001"
#     will maintain constant lr=0.001 for the entire training:
#
#   * "lin_decay_0.03_0.0001_0.75"
#     will start with lr=0.03 and linearly lower it to lr=0.0001 during the
#     first 75% of training
#
#   * "exp_decay_0.03_0.0001_0.5_5"
#     will start with lr=0.03 and exponentially lower it to lr=0.0001 during
#     the first 50% of training in 5 steps (ie. at 90%, 80%, 70%, 60% and 50%)
#
learner_lr_schedule: "const_0.0007"


# Env parameters
# The special "__include__" key allows to load them from another file.
# Keys listed here take precedence over keys loaded with __include__.
# See notes in `env.yml` for more info
env_kwargs:
  __include__: "config/env.yml"
  frames_per_step: 4
  reduced_action_set: false
  text_in_browser: "Do not close this window, training in progress..."

# List of gym wrappers to use for the env
# Each list element must be a dict with "module", "cls" and "kwargs" keys
env_wrappers: []
